{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312cbc46",
   "metadata": {},
   "source": [
    "# Alignment Ontology Generator\n",
    "## DPPO to CEON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a26865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment ontology serialized to: DPPO-CEON-alignment.ttl\n"
     ]
    }
   ],
   "source": [
    "# Python 3.11\n",
    "from pathlib import Path\n",
    "import re\n",
    "import openpyxl\n",
    "from rdflib import Graph, URIRef, BNode, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, OWL, DC, DCTERMS, XSD\n",
    "from collections import defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "mappings=[]\n",
    "EXCEL_PATH = Path(r\"./DPPO-CEON.xlsx\")\n",
    "online_path = (\"https://github.com/RichZele/DPP-DPPO-CEON-Ontology-Alignment/blob/main/documentations/DPPO-CEON.xlsx\")\n",
    "\n",
    "version = 0.1\n",
    "date = \"2026-01-23\"\n",
    "onto_comment = \"This ontology represents the alignment between the Digital Product Passport Ontology (DPPO) and Circular Economy Ontology Network (CEON).\"\n",
    "\n",
    "#EXCEL_PATH = Path(r\"C:/Users/kebreh/OneDrive - Jonkoping University/PostDoc/DPP-And-DPPO/Generators/DPPO-CEON.xlsx\")\n",
    "\n",
    "# Alignment ontology IRI and namespace.\n",
    "ONTO_IRI = URIRef(\"https://w3id.org/dpp/alignment/dppo-ceon/\")\n",
    "source_onto_IRI = URIRef(\"https://w3id.org/dppo/\")\n",
    "target_onto_IRI = URIRef(\"https://w3id.org/ceon/\")\n",
    "ALN = Namespace(str(ONTO_IRI) + \"#\")\n",
    "\n",
    "\n",
    "namespaces = {'xmlns': 'http://w3id.org/dpp/alignment/dpp-dppo/',\n",
    "              'xmlns:rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "              'xmlns:xsd': 'http://www.w3.org/2001/XMLSchema#'}\n",
    "\n",
    "added_entity = []\n",
    "\n",
    "def _clean_sheet_name(name: str) -> str:\n",
    "    s = name.strip()\n",
    "    s = re.sub(r\"\\s+\", \"_\", s)\n",
    "    s = re.sub(r\"[^A-Za-z0-9_]\", \"\", s)\n",
    "    return s or \"Sheet\"\n",
    "\n",
    "\n",
    "def _is_blank(value) -> bool:\n",
    "    return value is None or (isinstance(value, str) and value.strip() == \"\")\n",
    "\n",
    "\n",
    "def _as_uriref(value: str) -> URIRef:\n",
    "    v = value.strip()\n",
    "    return URIRef(v)\n",
    "\n",
    "\n",
    "def _add_axiom_with_annotations(g: Graph,\n",
    "                                source: URIRef,\n",
    "                                predicate: URIRef,\n",
    "                                target: URIRef,\n",
    "                                mapping_id: str | None,\n",
    "                                notes: str | None,\n",
    "                                sheet_tag: str) -> None:\n",
    "    \"\"\"\n",
    "    Adds the axiom triple plus an OWL reified axiom node with annotations.\n",
    "    \"\"\"\n",
    "    g.add((source, predicate, target))\n",
    "\n",
    "    ax = BNode()\n",
    "    g.add((ax, RDF.type, OWL.Axiom))\n",
    "    g.add((ax, OWL.annotatedSource, source))\n",
    "    g.add((ax, OWL.annotatedProperty, predicate))\n",
    "    g.add((ax, OWL.annotatedTarget, target))\n",
    "\n",
    "    if mapping_id and mapping_id.strip():\n",
    "        g.add((ax, DC.identifier, Literal(mapping_id.strip())))\n",
    "\n",
    "    if notes and notes.strip():\n",
    "        g.add((ax, RDFS.comment, Literal(notes.strip())))\n",
    "\n",
    "    # Provenance so you can trace which worksheet produced the axiom.\n",
    "    g.add((ax, DCTERMS.source, Literal(sheet_tag)))\n",
    "\n",
    "\n",
    "def _add_entity(g:Graph,\n",
    "               entity: URIRef,\n",
    "               entity_type: str | None) -> None:\n",
    "    if entity_type.strip() == \"Class\":\n",
    "        g.add((entity, RDF.type, OWL.Class))\n",
    "        added_entity.append(entity)\n",
    "    if entity_type.strip() == \"ObjectProperty\":\n",
    "        g.add((entity, RDF.type, OWL.ObjectProperty))\n",
    "        added_entity.append(entity)\n",
    "    if entity_type.strip() == \"DataProperty\":\n",
    "        g.add((entity, RDF.type, OWL.DatetypeProperty))\n",
    "        added_entity.append(entity)\n",
    "\n",
    "def _get_entity_type(entity_type: str | None) -> None:\n",
    "    if entity_type.strip() == \"Class\":\n",
    "        return OWL.Class\n",
    "    if entity_type.strip() == \"ObjectProperty\":\n",
    "        return OWL.ObjectProperty\n",
    "        added_entity.append(entity)\n",
    "    if entity_type.strip() == \"DataProperty\":\n",
    "        return OWL.DatetypeProperty\n",
    "    \n",
    "\n",
    "def _add_axiom_with_sssom_annotations(g: Graph,\n",
    "                                source: URIRef,\n",
    "                                predicate: URIRef,\n",
    "                                target: URIRef,\n",
    "                                mapping_id: str | None,\n",
    "                                notes: str | None,\n",
    "                                sheet_tag: str,\n",
    "                                source_label: str | None,\n",
    "                                target_label: str | None,\n",
    "                                source_type: str | None,\n",
    "                                target_type: str | None,) -> None:\n",
    "    \"\"\"\n",
    "    Adds the axiom triple plus an OWL reified axiom node with annotations.\n",
    "    \"\"\"\n",
    "    _add_entity(g, source, source_type)\n",
    "    _add_entity(g, target, target_type)\n",
    "    g.add((source, predicate, target))\n",
    "\n",
    "    sssom = Namespace(\"https://w3id.org/sssom/\")\n",
    "    semapv = Namespace(\"https://w3id.org/semapv/vocab/\")\n",
    "\n",
    "    g.bind(\"sssom\", sssom)\n",
    "    g.bind(\"semapv\", semapv)\n",
    "\n",
    "    #ax = BNode()\n",
    "\n",
    "    ax = _as_uriref(ONTO_IRI + Literal(mapping_id.strip()))\n",
    "    g.add((ax, RDF.type, sssom.Mapping))\n",
    "    g.add((ax, OWL.annotatedSource, source))\n",
    "    g.add((ax, OWL.annotatedProperty, predicate))\n",
    "    g.add((ax, OWL.annotatedTarget, target))\n",
    "    g.add((ax, sssom.mapping_justificatio, semapv.ManualMappingCuration))\n",
    "\n",
    "    if mapping_id and mapping_id.strip():\n",
    "        g.add((ax, DC.identifier, Literal(mapping_id.strip())))\n",
    "\n",
    "    if notes and notes.strip():\n",
    "        g.add((ax, RDFS.comment, Literal(notes.strip())))\n",
    "\n",
    "    if source_label and source_label.strip():\n",
    "        g.add((ax, sssom.subject_label, Literal(source_label.strip())))\n",
    "    \n",
    "    if target_label and target_label.strip():\n",
    "        g.add((ax, sssom.object_label, Literal(target_label.strip())))\n",
    "\n",
    "    if source_type and source_type.strip():\n",
    "        g.add((ax, sssom.subject_type, _get_entity_type(source_type)))\n",
    "\n",
    "    if target_type and target_type.strip():\n",
    "        g.add((ax, sssom.object_type, _get_entity_type(target_type)))\n",
    "        \n",
    "    # Provenance so you can trace which worksheet produced the axiom.\n",
    "    g.add((ax, DCTERMS.source, Literal(ONTO_IRI)))\n",
    "    mapping = defaultdict()\n",
    "    mapping['subject_id'] = source\n",
    "    mapping['object_id'] = target\n",
    "    mapping['subject_source'] = source_onto_IRI\n",
    "    mapping['object_source'] = target_onto_IRI\n",
    "    mapping['cardinality'] = '='\n",
    "    mapping['subject_label'] = source_label.strip()\n",
    "    mapping['object_label'] = target_label.strip()\n",
    "    mappings.append(mapping)\n",
    "    \n",
    "def _relation_to_predicate(alignment_relation: str,\n",
    "                           source_entity_type: str,\n",
    "                           target_entity_type: str) -> URIRef:\n",
    "    \"\"\"\n",
    "    Maps the spreadsheet relation token to an RDF predicate.\n",
    "    Extend this mapping as your template grows.\n",
    "    \"\"\"\n",
    "    rel = alignment_relation.strip().lower()\n",
    "\n",
    "    if rel in {\"equivalent_class\"}:\n",
    "        return OWL.equivalentClass\n",
    "    if rel in {\"subclass_of\"}:\n",
    "        return RDFS.subClassOf\n",
    "    if rel in {\"equivalent_property\", \"equivalent_object_property\", \"equivalent_data_property\"}:\n",
    "        return OWL.equivalentProperty\n",
    "    if rel in {\"subproperty_of\", \"sub_property_of\"}:\n",
    "        return RDFS.subPropertyOf\n",
    "    if rel in {\"same_as\"}:\n",
    "        return OWL.sameAs\n",
    "\n",
    "    # Conservative default. You should not silently invent semantics.\n",
    "    raise ValueError(f\"Unsupported alignment_relation '{alignment_relation}' for types \"\n",
    "                     f\"'{source_entity_type}' -> '{target_entity_type}'.\")\n",
    "\n",
    "\n",
    "def _apply_direction(source: URIRef,\n",
    "                     predicate: URIRef,\n",
    "                     target: URIRef,\n",
    "                     direction: str) -> list[tuple[URIRef, URIRef, URIRef]]:\n",
    "    \"\"\"\n",
    "    Returns one or two triples depending on direction.\n",
    "    \"\"\"\n",
    "    d = (direction or \"\").strip().lower()\n",
    "\n",
    "    if d == \"source_to_target\" or d == \"\":\n",
    "        return [(source, predicate, target)]\n",
    "\n",
    "    if d == \"target_to_source\":\n",
    "        return [(target, predicate, source)]\n",
    "\n",
    "    if d == \"bidirectional\":\n",
    "        # For symmetric predicates, this will produce redundant statements.\n",
    "        # That redundancy is acceptable, but you can optimize if you care.\n",
    "        return [(source, predicate, target), (target, predicate, source)]\n",
    "\n",
    "    raise ValueError(f\"Unsupported direction '{direction}'.\")\n",
    "\n",
    "\n",
    "def build_alignment_graph(excel_path: Path) -> Graph:\n",
    "    wb = openpyxl.load_workbook(excel_path, data_only=True)\n",
    "\n",
    "    g = Graph()\n",
    "    g.bind(\"owl\", OWL)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "    g.bind(\"dc\", DC)\n",
    "    g.bind(\"dcterms\", DCTERMS)\n",
    "    g.bind(\"aln\", ALN)\n",
    "\n",
    "    # Ontology header\n",
    "    g.add((ONTO_IRI, RDF.type, OWL.Ontology))\n",
    "    g.add((ONTO_IRI, RDFS.label, Literal(\"Alignment ontology: DPPO to CEON\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.source, Literal(str(excel_path))))\n",
    "\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        sheet_tag = _clean_sheet_name(sheet_name)\n",
    "\n",
    "        # Row 1 is header, row 2 is guidance, data starts at row 3.\n",
    "        headers = [c.value for c in ws[1]]\n",
    "        if any(_is_blank(h) for h in headers):\n",
    "            raise ValueError(f\"Header row has blank columns in sheet '{sheet_name}'.\")\n",
    "\n",
    "        header_index = {str(h).strip(): i for i, h in enumerate(headers)}\n",
    "\n",
    "        required = [\n",
    "            \"mapping_id\",\n",
    "            \"source_entity_type\",\n",
    "            \"source_iri\",\n",
    "            \"target_entity_type\",\n",
    "            \"target_iri\",\n",
    "            \"alignment_relation\",\n",
    "            \"direction\",\n",
    "            \"mapping_notes & justification\",\n",
    "        ]\n",
    "        missing = [c for c in required if c not in header_index]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns in sheet '{sheet_name}': {missing}\")\n",
    "\n",
    "        for row in ws.iter_rows(min_row=3, values_only=True):\n",
    "            # Skip empty rows\n",
    "            if all(_is_blank(v) for v in row):\n",
    "                continue\n",
    "\n",
    "            mapping_id = row[header_index[\"mapping_id\"]]\n",
    "            source_entity_type = row[header_index[\"source_entity_type\"]]\n",
    "            source_iri = row[header_index[\"source_iri\"]]\n",
    "            target_entity_type = row[header_index[\"target_entity_type\"]]\n",
    "            target_iri = row[header_index[\"target_iri\"]]\n",
    "            alignment_relation = row[header_index[\"alignment_relation\"]]\n",
    "            direction = row[header_index[\"direction\"]]\n",
    "            notes = row[header_index[\"mapping_notes & justification\"]]\n",
    "\n",
    "            # Skip malformed rows but do not silently accept them.\n",
    "            if _is_blank(source_iri) or _is_blank(target_iri) or _is_blank(alignment_relation):\n",
    "                raise ValueError(f\"Malformed mapping row in sheet '{sheet_name}'. \"\n",
    "                                 f\"mapping_id='{mapping_id}' source_iri='{source_iri}' target_iri='{target_iri}' \"\n",
    "                                 f\"alignment_relation='{alignment_relation}'\")\n",
    "\n",
    "            s = _as_uriref(str(source_iri))\n",
    "            t = _as_uriref(str(target_iri))\n",
    "\n",
    "            pred = _relation_to_predicate(\n",
    "                str(alignment_relation),\n",
    "                str(source_entity_type or \"\"),\n",
    "                str(target_entity_type or \"\"),\n",
    "            )\n",
    "\n",
    "            triples = _apply_direction(s, pred, t, str(direction or \"\"))\n",
    "\n",
    "            for ss, pp, tt in triples:\n",
    "                _add_axiom_with_annotations(\n",
    "                    g=g,\n",
    "                    source=ss,\n",
    "                    predicate=pp,\n",
    "                    target=tt,\n",
    "                    mapping_id=str(mapping_id) if not _is_blank(mapping_id) else None,\n",
    "                    notes=str(notes) if not _is_blank(notes) else None,\n",
    "                    sheet_tag=sheet_tag,\n",
    "                )\n",
    "\n",
    "    return g\n",
    "\n",
    "def build_alignment_sssom_graph(excel_path: Path) -> Graph:\n",
    "    wb = openpyxl.load_workbook(excel_path, data_only=True)\n",
    "\n",
    "    g = Graph()\n",
    "    g.bind(\"owl\", OWL)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "    g.bind(\"dc\", DC)\n",
    "    g.bind(\"dcterms\", DCTERMS)\n",
    "\n",
    "\n",
    "   \n",
    "    # Ontology header\n",
    "    g.add((ONTO_IRI, RDF.type, OWL.Ontology))\n",
    "    #g.add((ONTO_IRI, DCTERMS.description, Literal(\"Alignment ontology: DPP to DPPO\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.title, Literal(\"The alignment ontology between DPPO and CEON\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.creator, Literal(\"Rahel Kebede\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.contributor, Literal(\"Rahel Kebede\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.contributor, Literal(\"Huanyu Li\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.contributor, Literal(\"Eva Blomqvist\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.license, Literal(\"https://creativecommons.org/licenses/by/4.0/\")))\n",
    "    g.add((ONTO_IRI, DCTERMS.source, Literal(str(online_path))))\n",
    "    g.add((ONTO_IRI, OWL.versionInfo, Literal(str(version))))\n",
    "    g.add((ONTO_IRI, DCTERMS.created, Literal(date, datatype=XSD.date)))\n",
    "    g.add((ONTO_IRI, RDFS.comment, Literal(onto_comment)))\n",
    "\n",
    "    g.add((OWL.annotatedProperty, RDF.type, RDF.Property))\n",
    "    g.add((OWL.annotatedSource, RDF.type, RDF.Property))\n",
    "    g.add((OWL.annotatedTarget, RDF.type, RDF.Property))\n",
    "\n",
    "\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        sheet_tag = _clean_sheet_name(sheet_name)\n",
    "\n",
    "        # Row 1 is header, row 2 is guidance, data starts at row 3.\n",
    "        headers = [c.value for c in ws[1]]\n",
    "        if any(_is_blank(h) for h in headers):\n",
    "            raise ValueError(f\"Header row has blank columns in sheet '{sheet_name}'.\")\n",
    "\n",
    "        header_index = {str(h).strip(): i for i, h in enumerate(headers)}\n",
    "\n",
    "        required = [\n",
    "            \"mapping_id\",\n",
    "            \"source_entity_type\",\n",
    "            \"source_iri\",\n",
    "            \"target_entity_type\",\n",
    "            \"target_iri\",\n",
    "            \"alignment_relation\",\n",
    "            \"direction\",\n",
    "            \"mapping_notes & justification\",\n",
    "        ]\n",
    "        missing = [c for c in required if c not in header_index]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns in sheet '{sheet_name}': {missing}\")\n",
    "\n",
    "        for row in ws.iter_rows(min_row=3, values_only=True):\n",
    "            # Skip empty rows\n",
    "            if all(_is_blank(v) for v in row):\n",
    "                continue\n",
    "\n",
    "            mapping_id = row[header_index[\"mapping_id\"]]\n",
    "            source_entity_type = row[header_index[\"source_entity_type\"]]\n",
    "            source_iri = row[header_index[\"source_iri\"]]\n",
    "            source_label = row[header_index[\"source_label\"]]\n",
    "            target_entity_type = row[header_index[\"target_entity_type\"]]\n",
    "            target_iri = row[header_index[\"target_iri\"]]\n",
    "            target_label = row[header_index[\"target_label\"]]\n",
    "            alignment_relation = row[header_index[\"alignment_relation\"]]\n",
    "            direction = row[header_index[\"direction\"]]\n",
    "            notes = row[header_index[\"mapping_notes & justification\"]]\n",
    "\n",
    "            # Skip malformed rows but do not silently accept them.\n",
    "            if _is_blank(source_iri) or _is_blank(target_iri) or _is_blank(alignment_relation):\n",
    "                raise ValueError(f\"Malformed mapping row in sheet '{sheet_name}'. \"\n",
    "                                 f\"mapping_id='{mapping_id}' source_iri='{source_iri}' target_iri='{target_iri}' \"\n",
    "                                 f\"alignment_relation='{alignment_relation}'\")\n",
    "\n",
    "            s = _as_uriref(str(source_iri))\n",
    "            t = _as_uriref(str(target_iri))\n",
    "\n",
    "            pred = _relation_to_predicate(\n",
    "                str(alignment_relation),\n",
    "                str(source_entity_type or \"\"),\n",
    "                str(target_entity_type or \"\"),\n",
    "            )\n",
    "\n",
    "            triple = [(s, pred, t)]\n",
    "\n",
    "            for ss, pp, tt in triple:\n",
    "                _add_axiom_with_sssom_annotations(\n",
    "                    g=g,\n",
    "                    source=ss,\n",
    "                    predicate=pp,\n",
    "                    target=tt,\n",
    "                    mapping_id=str(mapping_id) if not _is_blank(mapping_id) else None,\n",
    "                    notes=str(notes) if not _is_blank(notes) else None,\n",
    "                    sheet_tag=sheet_tag,\n",
    "                    source_label=source_label,\n",
    "                    target_label=target_label,\n",
    "                    source_type=source_entity_type,\n",
    "                    target_type=target_entity_type\n",
    "                )\n",
    "\n",
    "    return g\n",
    "\n",
    "def generate_simple_rdf_file(mappings_lst, onto1_name, onto2_name, output_path = './'):\n",
    "    # Create the root element\n",
    "    onto1_url = mappings_lst[0]['subject_source']\n",
    "    onto2_url = mappings_lst[0]['object_source']\n",
    "    xml_node = ET.Element(\"xml\", version=\"1.0\", encoding=\"UTF-8\")\n",
    "    root = ET.Element(\"rdf:RDF\", attrib={'xmlns': namespaces['xmlns'], 'xmlns:rdf': namespaces['xmlns:rdf'], 'xmlns:xsd': namespaces['xmlns:xsd']})\n",
    "    # Create sub-elements\n",
    "    alignment_element = ET.SubElement(root, \"Alignment\")\n",
    "    xml_element = ET.SubElement(alignment_element, \"xml\")\n",
    "    xml_element.text = 'yes'\n",
    "    level_element = ET.SubElement(alignment_element, \"level\")\n",
    "    level_element.text = '0'\n",
    "    onto1_element = ET.SubElement(alignment_element, \"onto1\")\n",
    "    onto1_element.text = onto1_url\n",
    "    onto2_element = ET.SubElement(alignment_element, \"onto2\")\n",
    "    onto2_element.text = onto2_url\n",
    "    url1_element = ET.SubElement(alignment_element, \"url1\")\n",
    "    url1_element.text = onto1_url\n",
    "    url2_element = ET.SubElement(alignment_element, \"url2\")\n",
    "    url2_element.text = onto2_url\n",
    "    for mapping in mappings_lst:\n",
    "        mapping_element = ET.SubElement(alignment_element, \"map\")\n",
    "        cell_element = ET.SubElement(mapping_element, \"cell\")\n",
    "        entity1_element = ET.SubElement(cell_element, \"entity1\", attrib={'rdf:resource': mapping['subject_id']})\n",
    "        entity2_element = ET.SubElement(cell_element, \"entity2\", attrib={'rdf:resource': mapping['object_id']})\n",
    "        #measure_element = ET.SubElement(cell_element, \"measure\", attrib={'rdf:datatype': 'xsd:float'})\n",
    "        #measure_element.text=str(mapping['confidence'])\n",
    "        relation_element = ET.SubElement(cell_element, \"relation\")\n",
    "        relation_element.text=mapping['cardinality']\n",
    "    #tree = ET.ElementTree(xml_node)\n",
    "    tree = ET.ElementTree(root)\n",
    "    #tree._setroot(root)  # Set the root element\n",
    "    ET.indent(tree, space=\"  \", level=0)\n",
    "    alignment_file = '{output}{onto1}-{onto2}.rdf'.format(output=output_path, onto1=onto1_name, onto2=onto2_name)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    with open(alignment_file, \"wb\") as file:\n",
    "        tree.write(file, xml_declaration=True, method='xml', encoding='UTF-8')\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    store = build_alignment_sssom_graph(EXCEL_PATH)\n",
    "\n",
    "    output_path = EXCEL_PATH.parent / \"DPPO-CEON-alignment.ttl\"\n",
    "\n",
    "    store.serialize(\n",
    "        destination=str(output_path),\n",
    "        format=\"turtle\"\n",
    "    )\n",
    "    generate_simple_rdf_file(mappings,  'dppo', 'ceon')\n",
    "    print(f\"Alignment ontology serialized to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab44274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
